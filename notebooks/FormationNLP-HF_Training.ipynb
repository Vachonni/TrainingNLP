{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Obtaining file:///mnt/batch/tasks/shared/LS_root/mounts/clusters/med4c32g/code/Users/nicholas.vachon/TrainingNLP\n","Installing collected packages: TrainingNLP\n","  Attempting uninstall: TrainingNLP\n","    Found existing installation: TrainingNLP 0.0.1\n","    Uninstalling TrainingNLP-0.0.1:\n","      Successfully uninstalled TrainingNLP-0.0.1\n","  Running setup.py develop for TrainingNLP\n","Successfully installed TrainingNLP\n"]}],"source":["# # ONLY RUN WHEN IN AZURE\n","# import os\n","\n","# os.chdir('..')\n","# !pip install -e ."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["import os\n","\n","import pandas as pd\n","\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback\n","from datasets import Dataset\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","\n","import config\n","\n","# Print data example with complete content of column 'review'\n","pd.set_option('display.max_colwidth', None)"]},{"cell_type":"markdown","metadata":{"id":"mPUbBVWaygyc"},"source":["# **Consort - Formation NLP**\n","\n","## Introduction - Analyse de sentiments\n","\n","Objectif: Déterminer le sentiment d'un texte à l'aide de différentes techniques.\n","\n","![2-Figure2-1.png](data:image/png;base64,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)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XA9KrI8gmu-M"},"source":["\n","### Approche lexicale \n","(*Lexicon or Rule-Based approach*)\n","  - RegEx\n","  - NLTK\n","  - SpaCy\n","\n","### Machine Learning\n","  - Modèles à taille fixe\n","    - Bag of words\n","  - Modèles réccurents\n","    - CBOW\n","  - Modèles transformeurs\n","    - À affiner (fine-tune)\n","    - HuggingFace Sentiment Analysis\n","    - Google's API (sans création de compte)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6SQGpsgnoDpC"},"source":["# Données\n","\n","Jeu de données pour l'analyse de sentiments: Avis des utilisateurs d'Allociné.fr disponible ici: https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/tree/master/allocine_dataset\n","\n","Il contient 100 000 avis positifs et 100 000 avis négatifs répartis en 3 répartitions équilibrées : train (160 000 avis), val (20 000) et test (20 000).\n","\n","**NOTE:** Afin d'optimiser le temps de calcul pour cet exercice, nous allons réduire l'ensemble test 1000. "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Load data\n","train_data = pd.read_csv(config.base_dir + '/Data/train_data.csv', usecols=['review', 'polarity'])\n","val_data = pd.read_csv(config.base_dir + '/Data/val_data.csv', usecols=['review', 'polarity'])\n","test_data = pd.read_csv(config.base_dir + '/Data/prepro_test_data.csv', usecols=['review', 'polarity'])\n"]},{"cell_type":"markdown","metadata":{},"source":["## Préparation des données pour les transformers de HuggingFace"]},{"cell_type":"markdown","metadata":{},"source":["### datasets.Dataset"]},{"cell_type":"markdown","metadata":{},"source":["Pour la classification de texte, les modèles de HuggingFace requièrent des noms de colonnes spécifiques: `text` et `label`.\n","\n","Ensuite, les données doivent être converties en un objet `Dataset` de HuggingFace."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Transform data to fit HuggingFace datasets\n","def transform_to_dataset(data: pd.DataFrame) -> Dataset:\n","    dataset = Dataset.from_pandas(data)\n","    dataset = dataset.rename_column(\"review\", \"text\")\n","    dataset = dataset.rename_column(\"polarity\", \"label\")\n","    return dataset\n","\n","train_dataset = transform_to_dataset(train_data)\n","val_dataset = transform_to_dataset(val_data)\n","test_dataset = transform_to_dataset(test_data)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["{'text': 'Si vous cherchez du cinéma abrutissant à tous les étages,n\\'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l\\'on se dirige vers la banlieue,on y trouve tout plein d\\'intégristes musulmans prêts à faire sauter le caisson d\\'une ambassadrice américaine.Nauséeux.Alors on se dit qu\\'on va au moins pouvoir apprécier la déconnade d\\'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d\\'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l\\'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l\\'appui.Sinon,il n\\'y a aucun scénario.Seulement,des poursuites débiles sur l\\'autoroute,Travolta qui étale 10 mecs à l\\'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu\\'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c\\'est \"hénaurme\",c\\'est juste de la daube dans la droite lignée d\\'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".',\n"," 'label': 0}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0]"]},{"cell_type":"markdown","metadata":{},"source":["### Tokenizer"]},{"cell_type":"markdown","metadata":{},"source":["Finalement, les données sont tokenizées et encodées pour être utilisées par les modèles de HuggingFace. \n","\n","Le tokenizer est un objet qui permet de transformer les mots en nombres (identifiants) et de les encoder en tenseurs. \n","\n","Il est lié au modèle que l'on souhaite utiliser. Nous allons utiliser comme base, le même modèle de base que celui utilisé par \"cardiffnlp/camembert-base-tweet-sentiment-fr\" (exercice précédent), soit \"camembert-base\"."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["MODEL_NAME = \"camembert-base\"\n","\n","# Load the pre-trained model and tokenizer\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ead8fadab7f41d7a1019ad9bd1a537b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/160000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb77ff85947b490d80e13530c8e64020","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1b315f2bc474f929d4c393ddd6112dc","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","\n","token_train_datasets = train_dataset.map(tokenize_function, batched=True)\n","token_val_datasets = val_dataset.map(tokenize_function, batched=True)\n","token_test_datasets = test_dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["text:Si vous cherchez du cinéma abrutissant à tous les étages,n'ayant aucune peur du cliché en castagnettes et moralement douteux,\"From Paris with love\" est fait pour vous.Toutes les productions Besson,via sa filière EuropaCorp ont de quoi faire naître la moquerie.Paris y est encore une fois montrée comme une capitale exotique,mais attention si l'on se dirige vers la banlieue,on y trouve tout plein d'intégristes musulmans prêts à faire sauter le caisson d'une ambassadrice américaine.Nauséeux.Alors on se dit qu'on va au moins pouvoir apprécier la déconnade d'un classique buddy-movie avec le jeune agent aux dents longues obligé de faire équipe avec un vieux lou complètement timbré.Mais d'un côté,on a un Jonathan Rhys-meyers fayot au possible,et de l'autre un John Travolta en total délire narcissico-badass,crâne rasé et bouc proéminent à l'appui.Sinon,il n'y a aucun scénario.Seulement,des poursuites débiles sur l'autoroute,Travolta qui étale 10 mecs à l'arme blanche en 8 mouvements(!!)ou laisse son associé se faire démolir la tronche pendant qu'il scrute à la jumelle.Ca pourrait être un plaisir coupable,tellement c'est \"hénaurme\",c'est juste de la daube dans la droite lignée d'un \"Transporteur\",\"Taken\"ou \"Banlieue 13\".\n","label:0\n","input_ids:[5, 168, 39, 3162, 25, 1545, 29470, 2927, 15, 117, 19, 9339, 7, 255, 11, 3276, 771, 1020, 25, 16736, 22, 203, 11918, 5974, 10, 14, 4382, 131, 25154, 7, 130, 449, 6985, 300, 1466, 13748, 130, 30, 82, 24, 39, 9, 9595, 80, 19, 10473, 29601, 7, 7650, 77, 7705, 23693, 12820, 286, 96, 8, 484, 85, 10707, 13, 30752, 9, 7987, 102, 30, 143, 28, 151, 3133, 35, 79, 28, 2117, 16647, 7, 2044, 1425, 86, 17, 11, 88, 48, 5350, 224, 13, 8506, 7, 88, 102, 396, 66, 658, 18, 11, 21672, 1350, 4721, 4248, 15, 85, 7481, 16, 19465, 18, 11, 70, 21, 30157, 2606, 9, 607, 55, 15579, 914, 9, 20900, 91, 48, 227, 46, 11, 88, 198, 36, 175, 351, 5593, 13, 2366, 88, 16456, 18, 11, 59, 1584, 21, 26032, 3337, 26, 1577, 4518, 42, 16, 393, 6079, 68, 4111, 3070, 5683, 8, 85, 815, 42, 23, 1621, 17, 308, 1708, 21, 11123, 9545, 9, 6482, 18, 11, 59, 423, 7, 88, 33, 23, 14799, 16398, 105, 10, 26, 573, 6239, 10, 3385, 105, 1102, 36, 384, 7, 231, 8, 17, 11, 369, 23, 3112, 3724, 16279, 55, 22, 1458, 12287, 49, 5462, 9218, 675, 26, 18756, 636, 10, 7, 11655, 20429, 23587, 14, 20106, 909, 4940, 4443, 15, 17, 11, 6064, 9, 4066, 2600, 7, 62, 49, 11, 105, 33, 631, 3949, 9, 229, 2866, 2918, 7, 1294, 17245, 22568, 10, 32, 17, 11, 11234, 7, 15321, 16279, 55, 31, 21, 11758, 239, 6438, 15, 17, 11, 6123, 2188, 22, 344, 3017, 413, 2074, 53, 308, 1150, 58, 4003, 48, 85, 22212, 81, 13, 26120, 339, 46, 11, 62, 18653, 35, 15, 13, 17012, 9, 11852, 575, 98, 23, 593, 7289, 7, 110, 12434, 60, 11, 41, 87, 133, 9411, 297, 573, 517, 216, 11, 41, 390, 8, 13, 18, 10434, 29, 13, 991, 12355, 18, 11, 59, 87, 25524, 3108, 601, 517, 130, 12979, 6840, 130, 308, 87, 385, 364, 6925, 35, 560, 623, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","attention_mask:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}],"source":["for k,v in token_train_datasets[0].items():\n","    print(f\"{k}:{v}\")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["'<s> Si vous cherchez'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode([5, 168, 39, 3162])"]},{"cell_type":"markdown","metadata":{},"source":["# Fine-tuning de modèles pré-entrainés"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='11' max='30000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   11/30000 03:14 < 180:12:32, 0.05 it/s, Epoch 0.00/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='106' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [106/313 48:55 < 1:36:27, 0.04 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     20\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     21\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:1914\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1911\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1914\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1916\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2268\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:3019\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3016\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3018\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3019\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:3208\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3205\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3207\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3208\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3209\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3210\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:3425\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   3423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   3424\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3425\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3426\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   3428\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/trainer.py:2758\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2757\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2758\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2759\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2760\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:1063\u001b[0m, in \u001b[0;36mCamembertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1063\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1075\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:888\u001b[0m, in \u001b[0;36mCamembertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    879\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    881\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    882\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    883\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    887\u001b[0m )\n\u001b[0;32m--> 888\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    901\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:538\u001b[0m, in \u001b[0;36mCamembertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    527\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    528\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    529\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    535\u001b[0m         output_attentions,\n\u001b[1;32m    536\u001b[0m     )\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:427\u001b[0m, in \u001b[0;36mCamembertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    417\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:354\u001b[0m, in \u001b[0;36mCamembertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    346\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 354\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    364\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/transformers/models/camembert/modeling_camembert.py:280\u001b[0m, in \u001b[0;36mCamembertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    277\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Normalize the attention scores to probabilities.\u001b[39;00m\n\u001b[0;32m--> 280\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_probs)\n","File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/nn/functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Define training arguments\n","training_args = TrainingArguments(\n","    output_dir=config.base_dir + '/Model',\n","    num_train_epochs=3,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=64,\n","    warmup_steps=500,\n","    weight_decay=0.01,\n","    logging_dir=config.base_dir + '/Logs',\n","    logging_steps=10,\n","    evaluation_strategy='steps',\n","    eval_steps=10,                   # PUT MORE AROUND 500\n","    load_best_model_at_end=True,\n","    metric_for_best_model='accuracy',\n","    greater_is_better=True,\n",")\n","\n","# Define trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=token_train_datasets,\n","    eval_dataset=token_val_datasets,\n","    compute_metrics=lambda pred: {'accuracy': accuracy_score(pred.label_ids, pred.predictions.argmax(-1)),\n","                                  'macro_f1': f1_score(pred.label_ids, pred.predictions.argmax(-1), average='macro')},\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",")\n","\n","# Train model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Evaluate model\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Predict test dataset\n","preds = trainer.predict(token_test_datasets)\n","preds = preds.predictions.argmax(-1)\n","\n","# Print classification report\n","print(classification_report(test_dataset.label, preds))"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter Search"]},{"cell_type":"markdown","metadata":{},"source":["Only run this if you have time to spare and ressources (memory). It takes a while to run."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"]},{"name":"stdout","output_type":"stream","text":["Best parameters:  {'clf__alpha': 0.1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 3)}\n"]}],"source":["# Create a pipeline\n","pipe = Pipeline([\n","    ('vect', CountVectorizer()),\n","    ('tfidf', TfidfTransformer()),\n","    ('clf', MultinomialNB()),\n","])\n","\n","# Define the parameter grid\n","param_grid = {\n","    'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n","    'tfidf__use_idf': (True, False),\n","    'clf__alpha': (1.0, 0.5, 0.1, 0.00001),\n","}\n","\n","# Create a GridSearchCV object\n","grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, verbose=1)\n","\n","# Fit the GridSearchCV object to the data\n","grid_search.fit(train_data['review'], train_data['polarity'])\n","\n","# Print the best parameters\n","print(\"Best parameters: \", grid_search.best_params_)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.94      0.93      0.93     10204\n","           1       0.92      0.94      0.93      9796\n","\n","    accuracy                           0.93     20000\n","   macro avg       0.93      0.93      0.93     20000\n","weighted avg       0.93      0.93      0.93     20000\n","\n"]}],"source":["# Use the best model to make predictions for the validation set\n","y_pred = grid_search.predict(val_data['review'])\n","\n","# Evaluate the predictions\n","print(classification_report(val_data['polarity'], y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["We'll be using this set-up even if we could test for Logistic Regression and Random Forest."]},{"cell_type":"markdown","metadata":{},"source":["# Predictions on test set"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      0.91      0.93       516\n","           1       0.90      0.94      0.92       484\n","\n","    accuracy                           0.93      1000\n","   macro avg       0.93      0.93      0.92      1000\n","weighted avg       0.93      0.93      0.93      1000\n","\n"]}],"source":["# Use the best model to make predictions for the validation set\n","y_pred = grid_search.predict(test_data['review'])\n","\n","# Evaluate the predictions\n","print(classification_report(test_data['polarity'], y_pred))"]},{"cell_type":"markdown","metadata":{},"source":["## Save results"]},{"cell_type":"markdown","metadata":{},"source":["### By example"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>polarity</th>\n","      <th>ML_Basic_3grams_TFIDF_NB</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Je n'ai pas aimé mais pourtant je lui mets 2 étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Un dessin animé qui brille par sa féerie et ses chansons.</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Si c'est là le renouveau du cinéma français, c'est tout de même foutrement chiant. Si l'objet est très stylisé et la tension palpable, le film paraît plutôt creux.</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Et pourtant on s’en Doutait !Second volet très mauvais, sans fraîcheur et particulièrement lourdingue. Quel dommage.</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Dans \"Casino\", Martin Scorsese nous plonge dans le monde des escrocs, bandits et magouilleurs de Las Vegas dans les années 70. Mené par un trio d'acteurs impeccable, le film peint la fin d'un âge d'or local doté de ses codes et de son vocabulaire, mais sans perdre le néophyte grâce au procédé utilisé : toute l'histoire est narrée par Joe Pesci et Robert De Niro selon leurs points de vue et, malgré le rythme très rapide, tout est très limpide, en particulier grâce à la caméra virtuose du réalisateur. À une cadence effrénée et sur une bande originale parfaite, les scènes se succèdent et racontent une multitude de petites histoires qui, sans rien laisser paraître, vont actionner le mécanisme de la chute de Sam Rothstein. Ainsi, \"Casino\" est une fresque magistrale qui pénètre le cœur et la psychologie des personnages sur plusieurs années, exerçant ainsi une fascination ineffable. C'est un conte sur la folie des grandeurs, le poids de la famille, l'attrait du pouvoir et la cécité amoureuse. C'est l'histoire d'une vie racontée d'un trait, comme si elle s'était écoulée en un éclair, d'un point A vers un point B, point B qui, grâce à un magnifique plan final et la voix off appropriée,ne s'avère être qu'un point A'.</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Avant le dessin animé diffusé constamment sur Nickelodeon, il y avait ce film sorti sur grand écran. Si vous n’aimez pas le dessin animé, vous n’aimerez surement pas le film. En effet, le long-métrage est tout aussi mauvais que le dessin animé. Les séquences drôles sont rares. Le seul intérêt du film est le personnage Sheen, totalement délirant et hilarant. Si le film était centré rien que sur lui, je suis sur qu’il aurait été plus amusant.</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Séance de rattrapage pour un film que j’avais bêtement raté à sa sortie. Mais le DVD a ceci de bien, comme le livre : Il vous permet de posséder une œuvre, la garder près de vous, la reprendre quand elle vous manque. Et \"Blanca Nieves\" est vraiment une œuvre. Une œuvre d’art. Un chef d’œuvre.</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Nostalgie, mélancolie, dialogue écrit parfaitement d'un réalisme sans superflu, casting idéal, beauté des paysages, reconstitution sublime... que dire d'autre ?! Un film français réussi, un drame sentimentale couplé avec une histoire d'amitié presque sans parole... Superbe !</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Téléfilm vide de sens dont la seule et unique ambition est de faire de l'audimat en utilisant la plastique de son interprète. L'histoire aligne sans aucun scrupule les pires clichés d'un \"concept\" usé jusqu'à la corde. Moche mais généreuse, victime de méchants juste méchants, elle élabore une vengeance lorsqu'elle devient sculpturale. C'est d'une paresse sans nom, le réalisateur se tape de la mise en scène, et les acteurs sont pathétiques. Inutile de dire que la VF n'arrange pas les choses. Le film télé débile par excellence. Nullissime du début à la fin.</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         review  \\\n","0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)   \n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Je n'ai pas aimé mais pourtant je lui mets 2 étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.   \n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Un dessin animé qui brille par sa féerie et ses chansons.   \n","3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Si c'est là le renouveau du cinéma français, c'est tout de même foutrement chiant. Si l'objet est très stylisé et la tension palpable, le film paraît plutôt creux.   \n","4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Et pourtant on s’en Doutait !Second volet très mauvais, sans fraîcheur et particulièrement lourdingue. Quel dommage.   \n","..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n","995  Dans \"Casino\", Martin Scorsese nous plonge dans le monde des escrocs, bandits et magouilleurs de Las Vegas dans les années 70. Mené par un trio d'acteurs impeccable, le film peint la fin d'un âge d'or local doté de ses codes et de son vocabulaire, mais sans perdre le néophyte grâce au procédé utilisé : toute l'histoire est narrée par Joe Pesci et Robert De Niro selon leurs points de vue et, malgré le rythme très rapide, tout est très limpide, en particulier grâce à la caméra virtuose du réalisateur. À une cadence effrénée et sur une bande originale parfaite, les scènes se succèdent et racontent une multitude de petites histoires qui, sans rien laisser paraître, vont actionner le mécanisme de la chute de Sam Rothstein. Ainsi, \"Casino\" est une fresque magistrale qui pénètre le cœur et la psychologie des personnages sur plusieurs années, exerçant ainsi une fascination ineffable. C'est un conte sur la folie des grandeurs, le poids de la famille, l'attrait du pouvoir et la cécité amoureuse. C'est l'histoire d'une vie racontée d'un trait, comme si elle s'était écoulée en un éclair, d'un point A vers un point B, point B qui, grâce à un magnifique plan final et la voix off appropriée,ne s'avère être qu'un point A'.   \n","996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Avant le dessin animé diffusé constamment sur Nickelodeon, il y avait ce film sorti sur grand écran. Si vous n’aimez pas le dessin animé, vous n’aimerez surement pas le film. En effet, le long-métrage est tout aussi mauvais que le dessin animé. Les séquences drôles sont rares. Le seul intérêt du film est le personnage Sheen, totalement délirant et hilarant. Si le film était centré rien que sur lui, je suis sur qu’il aurait été plus amusant.   \n","997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Séance de rattrapage pour un film que j’avais bêtement raté à sa sortie. Mais le DVD a ceci de bien, comme le livre : Il vous permet de posséder une œuvre, la garder près de vous, la reprendre quand elle vous manque. Et \"Blanca Nieves\" est vraiment une œuvre. Une œuvre d’art. Un chef d’œuvre.   \n","998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Nostalgie, mélancolie, dialogue écrit parfaitement d'un réalisme sans superflu, casting idéal, beauté des paysages, reconstitution sublime... que dire d'autre ?! Un film français réussi, un drame sentimentale couplé avec une histoire d'amitié presque sans parole... Superbe !   \n","999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Téléfilm vide de sens dont la seule et unique ambition est de faire de l'audimat en utilisant la plastique de son interprète. L'histoire aligne sans aucun scrupule les pires clichés d'un \"concept\" usé jusqu'à la corde. Moche mais généreuse, victime de méchants juste méchants, elle élabore une vengeance lorsqu'elle devient sculpturale. C'est d'une paresse sans nom, le réalisateur se tape de la mise en scène, et les acteurs sont pathétiques. Inutile de dire que la VF n'arrange pas les choses. Le film télé débile par excellence. Nullissime du début à la fin.   \n","\n","     polarity  ML_Basic_3grams_TFIDF_NB  \n","0           1                         1  \n","1           0                         0  \n","2           1                         1  \n","3           0                         1  \n","4           0                         0  \n","..        ...                       ...  \n","995         1                         1  \n","996         0                         0  \n","997         1                         1  \n","998         1                         1  \n","999         0                         0  \n","\n","[1000 rows x 3 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["test_data['ML_Basic_3grams_TFIDF_NB'] = y_pred\n","test_data "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>review</th>\n","      <th>polarity</th>\n","      <th>token_pred</th>\n","      <th>stem_pred</th>\n","      <th>lem_pred</th>\n","      <th>HF_pretrained_EN</th>\n","      <th>HF_pretrained_FR</th>\n","      <th>HF_pretrained_FR_clean</th>\n","      <th>ML_Basic_3grams_TFIDF_NB</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Je n'ai pas aimé mais pourtant je lui mets 2 étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Un dessin animé qui brille par sa féerie et ses chansons.</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Si c'est là le renouveau du cinéma français, c'est tout de même foutrement chiant. Si l'objet est très stylisé et la tension palpable, le film paraît plutôt creux.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Et pourtant on s’en Doutait !Second volet très mauvais, sans fraîcheur et particulièrement lourdingue. Quel dommage.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>995</td>\n","      <td>Dans \"Casino\", Martin Scorsese nous plonge dans le monde des escrocs, bandits et magouilleurs de Las Vegas dans les années 70. Mené par un trio d'acteurs impeccable, le film peint la fin d'un âge d'or local doté de ses codes et de son vocabulaire, mais sans perdre le néophyte grâce au procédé utilisé : toute l'histoire est narrée par Joe Pesci et Robert De Niro selon leurs points de vue et, malgré le rythme très rapide, tout est très limpide, en particulier grâce à la caméra virtuose du réalisateur. À une cadence effrénée et sur une bande originale parfaite, les scènes se succèdent et racontent une multitude de petites histoires qui, sans rien laisser paraître, vont actionner le mécanisme de la chute de Sam Rothstein. Ainsi, \"Casino\" est une fresque magistrale qui pénètre le cœur et la psychologie des personnages sur plusieurs années, exerçant ainsi une fascination ineffable. C'est un conte sur la folie des grandeurs, le poids de la famille, l'attrait du pouvoir et la cécité amoureuse. C'est l'histoire d'une vie racontée d'un trait, comme si elle s'était écoulée en un éclair, d'un point A vers un point B, point B qui, grâce à un magnifique plan final et la voix off appropriée,ne s'avère être qu'un point A'.</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>996</td>\n","      <td>Avant le dessin animé diffusé constamment sur Nickelodeon, il y avait ce film sorti sur grand écran. Si vous n’aimez pas le dessin animé, vous n’aimerez surement pas le film. En effet, le long-métrage est tout aussi mauvais que le dessin animé. Les séquences drôles sont rares. Le seul intérêt du film est le personnage Sheen, totalement délirant et hilarant. Si le film était centré rien que sur lui, je suis sur qu’il aurait été plus amusant.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>997</td>\n","      <td>Séance de rattrapage pour un film que j’avais bêtement raté à sa sortie. Mais le DVD a ceci de bien, comme le livre : Il vous permet de posséder une œuvre, la garder près de vous, la reprendre quand elle vous manque. Et \"Blanca Nieves\" est vraiment une œuvre. Une œuvre d’art. Un chef d’œuvre.</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>998</td>\n","      <td>Nostalgie, mélancolie, dialogue écrit parfaitement d'un réalisme sans superflu, casting idéal, beauté des paysages, reconstitution sublime... que dire d'autre ?! Un film français réussi, un drame sentimentale couplé avec une histoire d'amitié presque sans parole... Superbe !</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>999</td>\n","      <td>Téléfilm vide de sens dont la seule et unique ambition est de faire de l'audimat en utilisant la plastique de son interprète. L'histoire aligne sans aucun scrupule les pires clichés d'un \"concept\" usé jusqu'à la corde. Moche mais généreuse, victime de méchants juste méchants, elle élabore une vengeance lorsqu'elle devient sculpturale. C'est d'une paresse sans nom, le réalisateur se tape de la mise en scène, et les acteurs sont pathétiques. Inutile de dire que la VF n'arrange pas les choses. Le film télé débile par excellence. Nullissime du début à la fin.</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 10 columns</p>\n","</div>"],"text/plain":["      ID  \\\n","0      0   \n","1      1   \n","2      2   \n","3      3   \n","4      4   \n","..   ...   \n","995  995   \n","996  996   \n","997  997   \n","998  998   \n","999  999   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         review  \\\n","0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)   \n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Je n'ai pas aimé mais pourtant je lui mets 2 étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.   \n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Un dessin animé qui brille par sa féerie et ses chansons.   \n","3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Si c'est là le renouveau du cinéma français, c'est tout de même foutrement chiant. Si l'objet est très stylisé et la tension palpable, le film paraît plutôt creux.   \n","4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Et pourtant on s’en Doutait !Second volet très mauvais, sans fraîcheur et particulièrement lourdingue. Quel dommage.   \n","..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ...   \n","995  Dans \"Casino\", Martin Scorsese nous plonge dans le monde des escrocs, bandits et magouilleurs de Las Vegas dans les années 70. Mené par un trio d'acteurs impeccable, le film peint la fin d'un âge d'or local doté de ses codes et de son vocabulaire, mais sans perdre le néophyte grâce au procédé utilisé : toute l'histoire est narrée par Joe Pesci et Robert De Niro selon leurs points de vue et, malgré le rythme très rapide, tout est très limpide, en particulier grâce à la caméra virtuose du réalisateur. À une cadence effrénée et sur une bande originale parfaite, les scènes se succèdent et racontent une multitude de petites histoires qui, sans rien laisser paraître, vont actionner le mécanisme de la chute de Sam Rothstein. Ainsi, \"Casino\" est une fresque magistrale qui pénètre le cœur et la psychologie des personnages sur plusieurs années, exerçant ainsi une fascination ineffable. C'est un conte sur la folie des grandeurs, le poids de la famille, l'attrait du pouvoir et la cécité amoureuse. C'est l'histoire d'une vie racontée d'un trait, comme si elle s'était écoulée en un éclair, d'un point A vers un point B, point B qui, grâce à un magnifique plan final et la voix off appropriée,ne s'avère être qu'un point A'.   \n","996                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Avant le dessin animé diffusé constamment sur Nickelodeon, il y avait ce film sorti sur grand écran. Si vous n’aimez pas le dessin animé, vous n’aimerez surement pas le film. En effet, le long-métrage est tout aussi mauvais que le dessin animé. Les séquences drôles sont rares. Le seul intérêt du film est le personnage Sheen, totalement délirant et hilarant. Si le film était centré rien que sur lui, je suis sur qu’il aurait été plus amusant.   \n","997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Séance de rattrapage pour un film que j’avais bêtement raté à sa sortie. Mais le DVD a ceci de bien, comme le livre : Il vous permet de posséder une œuvre, la garder près de vous, la reprendre quand elle vous manque. Et \"Blanca Nieves\" est vraiment une œuvre. Une œuvre d’art. Un chef d’œuvre.   \n","998                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Nostalgie, mélancolie, dialogue écrit parfaitement d'un réalisme sans superflu, casting idéal, beauté des paysages, reconstitution sublime... que dire d'autre ?! Un film français réussi, un drame sentimentale couplé avec une histoire d'amitié presque sans parole... Superbe !   \n","999                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Téléfilm vide de sens dont la seule et unique ambition est de faire de l'audimat en utilisant la plastique de son interprète. L'histoire aligne sans aucun scrupule les pires clichés d'un \"concept\" usé jusqu'à la corde. Moche mais généreuse, victime de méchants juste méchants, elle élabore une vengeance lorsqu'elle devient sculpturale. C'est d'une paresse sans nom, le réalisateur se tape de la mise en scène, et les acteurs sont pathétiques. Inutile de dire que la VF n'arrange pas les choses. Le film télé débile par excellence. Nullissime du début à la fin.   \n","\n","     polarity  token_pred  stem_pred  lem_pred  HF_pretrained_EN  \\\n","0           1           1          1         1                 1   \n","1           0           0          0         0                 0   \n","2           1           1          1         1                 0   \n","3           0           0          0         0                 1   \n","4           0           0          0         0                 0   \n","..        ...         ...        ...       ...               ...   \n","995         1           0          0         0                 0   \n","996         0           0          0         0                 0   \n","997         1           1          1         1                 0   \n","998         1           1          1         1                 1   \n","999         0           0          0         0                 0   \n","\n","     HF_pretrained_FR  HF_pretrained_FR_clean  ML_Basic_3grams_TFIDF_NB  \n","0                   1                       1                         1  \n","1                   1                       0                         0  \n","2                   1                       1                         1  \n","3                   0                       0                         1  \n","4                   0                       0                         0  \n","..                ...                     ...                       ...  \n","995                 1                       0                         1  \n","996                 0                       0                         0  \n","997                 1                       1                         1  \n","998                 1                       1                         1  \n","999                 0                       0                         0  \n","\n","[1000 rows x 10 columns]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Check if pred_test_data.csv exists\n","if os.path.exists(config.base_dir + '/Data/pred_test_data.csv'):\n","    # If exists, read it and update it with new predictions\n","    pred_test_data = pd.read_csv(config.base_dir + '/Data/pred_test_data.csv')\n","    pred_test_data['ML_Basic_3grams_TFIDF_NB'] = test_data['ML_Basic_3grams_TFIDF_NB']\n","else:\n","    # If not, create it\n","    test_data.to_csv(config.base_dir + '/Data/pred_test_data.csv', index=False)\n","\n","pred_test_data"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["pred_test_data.to_csv(config.base_dir + '/Data/pred_test_data.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Comparaison analysis"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>accuracy</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>ML_Basic_3grams_TFIDF_NB</th>\n","      <td>0.925</td>\n","      <td>0.925</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          accuracy     f1\n","ML_Basic_3grams_TFIDF_NB     0.925  0.925"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# For the 3 different techniques, calculate the accuracy and F1 score\n","accuracy = []\n","f1 = []\n","for tech in ['ML_Basic_3grams_TFIDF_NB']:\n","    accuracy.append(accuracy_score(test_data['polarity'], test_data[tech]))\n","    f1.append(f1_score(test_data['polarity'], test_data[tech], average='micro'))\n","\n","df_comparsion = pd.DataFrame({'accuracy': accuracy, 'f1': f1}, index=['ML_Basic_3grams_TFIDF_NB'])\n","df_comparsion.sort_values('accuracy', ascending=False, inplace=True)\n","\n","df_comparsion\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["                        accuracy     f1\n","HF_pretrained_FR           0.824  0.824\n","HF_pretrained_FR_clean     0.799  0.799\n","lexi_token                 0.648  0.648\n","lexi_lem                   0.648  0.648\n","lexi_stem                  0.645  0.645\n","HF_pretrained_EN           0.639  0.639\n","                          accuracy     f1\n","ML_Basic_3grams_TFIDF_NB     0.925  0.925\n","HF_pretrained_FR             0.824  0.824\n","HF_pretrained_FR_clean       0.799  0.799\n","lexi_token                   0.648  0.648\n","lexi_lem                     0.648  0.648\n","lexi_stem                    0.645  0.645\n","HF_pretrained_EN             0.639  0.639\n"]}],"source":["# Check if comparsion_analysis.csv already exists \n","if os.path.exists(config.base_dir + '/Data/comparsion_analysis.csv'):\n","    # If yes, read it and update it with the new results\n","    df_comparsion_old = pd.read_csv(config.base_dir + '/Data/comparsion_analysis.csv', index_col=0)\n","    print(df_comparsion_old)\n","    df_comparsion_old.update(df_comparsion)\n","    df_comparsion_combined = pd.concat([df_comparsion_old, df_comparsion[~df_comparsion.index.isin(df_comparsion_old.index)]])\n","    df_comparsion_combined.sort_values('accuracy', ascending=False, inplace=True)\n","    # Save the updated DataFrame back to the CSV file\n","    df_comparsion_combined.to_csv(config.base_dir + '/Data/comparsion_analysis.csv')\n","    print(df_comparsion_combined)\n","else:\n","    df_comparsion.to_csv(config.base_dir + '/Data/comparsion_analysis.csv', index=True)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP99ATM1/D6U44NzkH8C2S7","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3.10 - SDK v2","language":"python","name":"python310-sdkv2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
